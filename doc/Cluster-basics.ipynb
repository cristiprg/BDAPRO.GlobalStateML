{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster usage\n",
    "\n",
    "## ibm-power-1 cluster\n",
    "\n",
    "### Getting Access\n",
    "\n",
    "- The cluster usage documentation is available at [1]. \n",
    "- In order to acquire access to the cluster, please email helpdesk@dima.tu-berlin.de with the following information\n",
    "  - name and surname\n",
    "  - email (if possible, supply a *.tu-berlin.de address)\n",
    "  - GitHub username\n",
    "  - purpose (thesis, project work, paper)\n",
    "  \n",
    "You will get\n",
    "- SSH access to the cluster (\\$SSH_USER and \\$SSH_PASS are sent in two separate emails),\n",
    "- GitHub access to this project\n",
    "- Slack access to the ibm-power-1 channel\n",
    "\n",
    "**Please make sure you read this instructions [1] carefully before using the cluster.**\n",
    "\n",
    "### Rules\n",
    "\n",
    "The right to execute experiments on the cluster is in general exclusive, and is acquired via a locking protocol by communicating with other cluster users in the ibm-power Slack channel.\n",
    "\n",
    "Before you go on the cluster, please make sure that\n",
    "\n",
    "- Nobody else is using by asking in the channel\n",
    "- There are no Java processes running under the peel user.\n",
    "- You announce that you are going on the cluster in Slack\n",
    "\n",
    "After you go off, make sure that\n",
    "\n",
    "- You cleanly shutdown all services running under peel\n",
    "- You cleanup produced experiment data\n",
    "- The stable HDFS instance is up and running\n",
    "- You announce that you are done in Slack\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Connecting\n",
    "\n",
    "The cluster is directly accessible only from the TUBIT network. If you are inside the network, you should be able to login as follows:\n",
    "\n",
    "`ssh $SSH_USER@ibm-power-1.dima.tu-berlin.de -D 1080`\n",
    "\n",
    "`sudo -iu hadoop`\n",
    "\n",
    "\n",
    "For faster without a password, we suggest to append your public SSH key to\n",
    "\n",
    " - `/home/hadoop/.ssh/authorized_keys`\n",
    " - `/home/$SSH_USER/.ssh/authorized_keys`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSH setup\n",
    "```\n",
    "ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" (email is optional)\n",
    "\n",
    "eval \"$(ssh-agent -s)\"\n",
    "\n",
    "ssh-add ~/.ssh/id_rsa\n",
    "\n",
    "pbcopy < ~/.ssh/id_rsa.pub\n",
    "\n",
    "Append to files listed above\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Port forwarding\n",
    "\n",
    "The -D 1080 option in the commands above sets up dynamic forwarding and opens a SOCKS proxy to ibm-power-1 on port 1080 as part of your ssh connection.\n",
    "\n",
    "This is equivalent to: \n",
    "\n",
    "\n",
    "This will allow you to access web services running on the cluster from your browser. To do that, configure a proxy plug-in like **FoxyProxy** with the following parameters:\n",
    "\n",
    "- Proxy host: localhost\n",
    "- Proxy type: SOCKS \n",
    "- Proxy port: 1080\n",
    "- Proxy pattern: *ibm-power-*.dima.tu-berlin.de/* (whitelist)\n",
    "\n",
    "\n",
    "You can monitor the status of the systems from the following interfaces:\n",
    "\n",
    "\n",
    "- [HDFS Interface (stable, running under hdfs)](http://ibm-power-1.dima.tu-berlin.de:44010)\n",
    "- [HDFS Interface (short-lived, running under hadoop)](http://ibm-power-1.dima.tu-berlin.de:45010)\n",
    "- [Flink (short-lived, running under hadoop)](http://ibm-power-1.dima.tu-berlin.de:8981)\n",
    "- [Spark (short-lived, running under hadoop)](http://ibm-power-1.dima.tu-berlin.de:8060)\n",
    "- Any other service running in cluster\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tmux\n",
    "\n",
    "What is a terminal multiplexer? \n",
    "\n",
    "It lets you switch easily between several programs in one terminal, detach them (they keep running in the background) and reattach them to a different terminal. And do a lot more\n",
    "\n",
    "The cheatsheet is available at [2].\n",
    "\n",
    "#### tmux windows:\n",
    "\n",
    "```\n",
    "<prefix> = ctrl-b. Use prefix-* to execute tmux commands\n",
    "- <prefix>-c creates new window\n",
    "- <prefix>-, rename window \n",
    "- <prefix>-p, previous window\n",
    "- <prefix>-n, next window\n",
    "- <prefix>-w, list open windows\n",
    "```\n",
    "\n",
    "\n",
    "#### tmux panes:\n",
    "```\n",
    "- <prefix>-% split the window vertically\n",
    "- <prefix>-:=>split-window\n",
    "- <prefix>-q-paneNo=> change panes\n",
    "- <prefix> & for killing a window\n",
    "- <prefix> x for killing a pane\n",
    "\n",
    "```\n",
    "#### tmux sessions:\n",
    "```\n",
    "- tmux new -s <session_name>\n",
    "- <prefix>-d detach from session. You can freely close the connection between remote and local.\n",
    "- tmux list-sessions\n",
    "- tmux attach -t <session_name>\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems\n",
    "\n",
    "\n",
    "- Download system\n",
    "- Configure master/slaves\n",
    "- Start cluster\n",
    "\n",
    "\n",
    "More in details about cluster setup are available at [3],[5] and configuration parameters at [4],[5].\n",
    "\n",
    "Keep in mind that once the configuration parameters are changed for running cluster, it must be restarted to get new parameters.\n",
    "\n",
    "Demos for Flink, Spark , Storm ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flink:\n",
    "- Start : flink_home_dir + \"bin/start-cluster.sh\"\n",
    "- Stop : flink_home + \"bin/stop-cluster.sh\"\n",
    "- Run job: flink_home + \"bin/flink\" , \"run\", project_dir + \"your_jar\", \"--confPath\",conf_file\n",
    "\n",
    "Spark:\n",
    "- Start: spark_home + \"sbin/start-all.sh\"\n",
    "- Stop: spark_home + \"sbin/stop-all.sh\"\n",
    "- Run job: spark_home + 'bin/spark-submit' ,'--class' ,'spark.benchmark.SparkBenchmark', project_dir + 'spark-benchmarks/target/spark-benchmarks-0.1.0.jar' , conf_file\n",
    "\n",
    "\n",
    "Storm:\n",
    "\n",
    "- Start zookeeper\n",
    "- Start nimbus: storm_home + 'bin/storm' + 'nimbus'\n",
    "- Start supervisors: storm_home + 'bin/storm' + 'supervisor'\n",
    "- Start ui: storm_home + 'bin/storm' ,'ui'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] https://github.com/stratosphere/peelconfig.ibm-power-1/wiki/Cluster-Usage-Guide\n",
    "[2] https://danielmiessler.com/study/tmux/#gs.nLmYg6Y\n",
    "[3] https://ci.apache.org/projects/flink/flink-docs-release-0.8/cluster_setup.html\n",
    "[4] https://ci.apache.org/projects/flink/flink-docs-master/setup/config.html\n",
    "[5] http://spark.apache.org/docs/latest/spark-standalone.html\n",
    "[6] http://storm.apache.org/releases/1.0.2/Setting-up-a-Storm-cluster.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
